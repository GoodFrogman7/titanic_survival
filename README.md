## Tools and Skills Used

### **Languages and Libraries**
- **Python**: Core programming language for data manipulation, analysis, and modeling.
- **Pandas**: Used for data cleaning, exploration, and manipulation.
- **NumPy**: Handled numerical operations and computations.
- **Matplotlib**: Created static visualizations to analyze trends and patterns.
- **Seaborn**: Designed advanced data visualizations, such as heatmaps and distribution plots.
- **Scikit-learn**: Built machine learning models, evaluated performance metrics, and implemented preprocessing techniques.
- **Joblib**: Saved and loaded trained models for reproducibility.

### **Machine Learning Techniques**
- **Logistic Regression**: Applied a fundamental classification algorithm to predict survival probabilities.
- **Random Forest**: Leveraged an ensemble-based machine learning model for improved accuracy.
- **Hyperparameter Tuning**: Optimized model performance using `GridSearchCV`.

### **Data Science Concepts**
- **Exploratory Data Analysis (EDA)**: Uncovered survival patterns by analyzing key factors such as gender, class, and age.
- **Feature Engineering**: Encoded categorical variables, handled missing data, and optimized feature selection for better model performance.
- **Correlation Analysis**: Explored relationships between features to identify influential variables.

### **Visualization Techniques**
- Designed insights-driven visualizations, including:
  - Survival rates by gender and passenger class.
  - Age distribution by survival.
  - Correlation heatmaps to analyze feature relationships.
  - Confusion matrices for evaluating classification results.
  - Feature importance plots for Random Forest.

### **Project Development and Version Control**
- **Git**: Used for version control of scripts, datasets, and visualizations.
- **GitHub**: Hosted and shared the project repository for accessibility.

### **Data Handling**
- **Kaggle Titanic Dataset**: Sourced, cleaned, and processed raw data for analysis and modeling.
- **CSV Management**: Saved intermediate outputs, such as cleaned datasets, predictions, and misclassified samples, to ensure reproducibility.

### **Key Skills Gained**
- **Data Cleaning**: Imputed missing values and addressed inconsistencies in the dataset.
- **Model Evaluation**: Assessed accuracy, precision, recall, and F1 scores to validate predictions.
- **Model Interpretability**: Analyzed feature importance to explain and justify model predictions.

---

